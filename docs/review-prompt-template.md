# CPA Question Review Prompt Template

## Revised Review Strategy: Generate-All-First

Based on our sample batch validation (96% accuracy - 24/25 approved), we've optimized the workflow to minimize ChatGPT rate limit concerns while maximizing review coverage.

### Workflow Overview

```
┌─────────────────────────────────────────────────────────────────────────┐
│  PHASE 1: GENERATION                                                    │
│  Generate ALL ~5,500 questions across 6 sections                        │
│  FAR (1,500) → AUD (1,000) → REG (1,200) → TCP (800) → BAR (500) → ISC  │
└─────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────┐
│  PHASE 2: CLAUDE FULL REVIEW (100%)                                     │
│  Different Claude instance reviews entire database                      │
│  Focus: Structure, format, taxonomy, duplicates, explanation quality    │
└─────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────┐
│  PHASE 3: GPT-4O STATISTICAL SAMPLE (5-10%)                             │
│  Random stratified sample: ~300-550 questions                           │
│  Focus: Technical accuracy, current standards, answer correctness       │
└─────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────┐
│  PHASE 4: REMEDIATION                                                   │
│  Fix issues found, re-sample affected sections if needed                │
└─────────────────────────────────────────────────────────────────────────┘
```

### Stage Details

| Stage | Model | Purpose | Volume | Rate Limit Concern |
|-------|-------|---------|--------|-------------------|
| **Generation** | Claude Opus 4.5 | Create questions | 5,500 questions | None (Pro plan) |
| **Full Review** | Claude (separate session) | Structure, taxonomy, duplicates | 100% (~5,500) | None (Pro plan) |
| **Spot-Check** | GPT-4o (ChatGPT Plus) | Accuracy verification | 5-10% (~300-550) | Low (1-2 sessions) |
| **Human Review** | You | Final validation of flagged items | As needed | N/A |

### Why Generate-All-First?

1. **Validated low error rate**: Sample batch showed 96% accuracy (24/25)
2. **Avoids ChatGPT rate limits**: GPT-4o only reviews ~300-550 questions total
3. **Claude handles bulk work**: No practical limits with Pro plan
4. **Statistical sampling is standard QA**: If 5% sample passes, database is reliable
5. **Faster overall throughput**: No review bottleneck during generation

### Statistical Sample Strategy

**Sample Size:**
- 5% sample = ~275 questions (minimum for statistical significance)
- 10% sample = ~550 questions (high confidence)

**Stratified Sampling (proportional by section):**
| Section | Total Questions | 5% Sample | 10% Sample |
|---------|-----------------|-----------|------------|
| FAR | 1,500 | 75 | 150 |
| AUD | 1,000 | 50 | 100 |
| REG | 1,200 | 60 | 120 |
| TCP | 800 | 40 | 80 |
| BAR | 500 | 25 | 50 |
| ISC | 500 | 25 | 50 |
| **Total** | **5,500** | **275** | **550** |

**Prioritize in sample:**
- All calculation questions
- All tax threshold questions
- Complex GAAP interpretations
- Any questions Claude flagged as uncertain

---

## Part 1: Claude Bulk Review Prompt

Use this in a **separate Claude session** (not the one generating questions) for initial review of ALL questions.

### Claude Review System Prompt

```
You are reviewing CPA exam practice questions for quality and accuracy. These questions were generated by another Claude instance, so be critical and look for:

1. STRUCTURAL ISSUES
- Missing or malformed fields
- Taxonomy mismatches (question doesn't fit topic/subtopic)
- Incorrect difficulty ratings
- Duplicate or near-duplicate questions

2. OBVIOUS ERRORS
- Questions with no clear correct answer
- Questions with multiple correct answers
- Grammatical issues or unclear wording
- Answer choices not parallel in structure

3. FORMAT COMPLIANCE
- All required fields present
- ID follows naming convention
- conceptTested is specific (not just repeating topic)
- questionFormat matches actual question type

Focus on catching structural and obvious issues. A separate GPT-4o review will verify factual accuracy.
```

### Claude Review Output Format

```json
{
  "questionId": "far-rev-001",
  "structureValid": true,
  "taxonomyCorrect": true,
  "issues": [],
  "flagForGptReview": false,
  "notes": ""
}
```

Set `flagForGptReview: true` for:
- Complex tax calculations
- Nuanced GAAP interpretations
- Any question you're uncertain about
- All calculation questions (to verify math)

---

## Part 2: GPT-4o Spot-Check Prompt (ChatGPT Plus)

For Use With: GPT-4o via ChatGPT Plus

Use for 10-20% of questions, prioritizing:
- All questions flagged by Claude review
- Random sample from each section
- All calculation questions
- All tax questions (currency concerns)

### GPT-4o System Prompt

```
You are a CPA exam content reviewer with expertise in:
- US GAAP (Financial Accounting Standards Codification)
- US GAAS (Auditing Standards - AICPA and PCAOB)
- US Federal Tax Law (IRC, Treasury Regulations)
- Business Law (UCC, Agency, Securities)

Your job is to review AI-generated CPA exam practice questions for accuracy, currency, and quality. You must be rigorous and flag any issues - it's better to flag a potential problem than to let an incorrect question through.

IMPORTANT: These questions were generated by Claude (Anthropic). Your role is to catch any errors, outdated information, or misconceptions that may have been introduced during generation.

Current standards to verify against (as of 2024-2025):
- Revenue Recognition: ASC 606 (NOT the old ASC 605)
- Leases: ASC 842 (NOT the old ASC 840) - operating leases ARE on balance sheet
- Credit Losses: CECL model (ASC 326)
- Tax Law: Post-TCJA (2017) with updates through 2024
- Goodwill: NOT amortized, tested for impairment annually
- LIFO: Allowed under US GAAP, NOT allowed under IFRS
```

---

## Review Prompt (Per Batch)

```
Review the following batch of CPA exam practice questions. For each question, evaluate:

## 1. ACCURACY (Most Critical)
- Is the marked correct answer actually correct under current US GAAP/GAAS/Tax Law?
- Is the explanation accurate and complete?
- Are there any outdated standards referenced?
- Could any of the "wrong" answers actually be defensible?

## 2. TAXONOMY
- Does the question fit the assigned topic and subtopic?
- Is the `conceptTested` field specific and accurate?
- Is the difficulty rating appropriate (easy/medium/hard)?
- Is the `questionFormat` correctly identified?

## 3. QUALITY
- Is the question clear and unambiguous?
- Is there exactly ONE clearly correct answer?
- Are the distractors (wrong answers) plausible but definitely wrong?
- Are answer choices parallel in grammatical structure?
- Does the explanation help the learner understand WHY?

## 4. EXAM AUTHENTICITY
- Does this feel like a real CPA exam question?
- Is the length/complexity appropriate for the stated difficulty?
- For calculation questions: Is the math setup realistic?

## Output Format

For EACH question, respond with this exact JSON structure:

{
  "questionId": "[the question's id field]",
  "status": "approved" | "needs-revision" | "reject",
  "correctAnswerVerified": true | false,
  "issues": [
    {
      "type": "accuracy" | "taxonomy" | "quality" | "outdated" | "ambiguous",
      "severity": "critical" | "major" | "minor",
      "field": "[which field has the issue: question, correctAnswer, explanation, options, topic, etc.]",
      "description": "[Specific description of the issue]",
      "suggestion": "[How to fix it, if applicable]"
    }
  ],
  "accuracyConfidence": "high" | "medium" | "low",
  "notes": "[Any additional observations]"
}

## Severity Definitions
- **critical**: Wrong answer marked as correct, or major factual error - MUST fix
- **major**: Ambiguous wording, outdated standard, misleading explanation - SHOULD fix
- **minor**: Style issue, could be clearer, minor taxonomy mismatch - NICE to fix

## Special Instructions

1. If you're unsure whether something is correct, mark `accuracyConfidence: "low"` and explain your uncertainty in notes.

2. For tax questions, note that tax law changes frequently. Flag anything you're uncertain about with "verify current law" in notes.

3. For calculation questions, actually work through the math to verify the correct answer.

4. Watch for these common AI-generated question issues:
   - Answers that are "too perfect" or use textbook language unrealistically
   - Scenarios that wouldn't occur in practice
   - Distractors that are obviously wrong (not plausible)
   - Questions that test trivia rather than understanding

5. If a question is fundamentally flawed (wrong answer, major conceptual error), mark as "reject" rather than "needs-revision".

---

## Questions to Review:

[PASTE QUESTIONS HERE IN JSON FORMAT]
```

---

## Example Review Output

```json
[
  {
    "questionId": "far-rev-001",
    "status": "approved",
    "correctAnswerVerified": true,
    "issues": [],
    "accuracyConfidence": "high",
    "notes": "Clean question, accurate under ASC 606."
  },
  {
    "questionId": "far-rev-002",
    "status": "needs-revision",
    "correctAnswerVerified": true,
    "issues": [
      {
        "type": "quality",
        "severity": "minor",
        "field": "options",
        "description": "Option D is too obviously wrong compared to other choices",
        "suggestion": "Replace with a more plausible distractor, perhaps referencing a common misconception about variable consideration"
      }
    ],
    "accuracyConfidence": "high",
    "notes": "Core content is correct, just needs stronger distractor."
  },
  {
    "questionId": "far-lease-015",
    "status": "reject",
    "correctAnswerVerified": false,
    "issues": [
      {
        "type": "outdated",
        "severity": "critical",
        "field": "correctAnswer",
        "description": "Question states operating leases are not recorded on balance sheet. This was true under ASC 840 but is INCORRECT under current ASC 842.",
        "suggestion": "Rewrite question to reflect ASC 842 requirements where lessees record ROU asset and lease liability for ALL leases (with limited exceptions)."
      }
    ],
    "accuracyConfidence": "high",
    "notes": "This appears to be based on pre-2019 lease accounting. Must be completely rewritten."
  },
  {
    "questionId": "reg-ind-042",
    "status": "needs-revision",
    "correctAnswerVerified": false,
    "issues": [
      {
        "type": "accuracy",
        "severity": "critical",
        "field": "explanation",
        "description": "The QBI deduction limitation for specified service trades or businesses (SSTBs) kicks in at different thresholds than stated. The explanation mentions $157,500/$315,000 but these phase-out thresholds are inflation-adjusted annually.",
        "suggestion": "Either use the current year's thresholds or phrase as 'the applicable threshold' without specific numbers that will become outdated."
      }
    ],
    "accuracyConfidence": "medium",
    "notes": "Verify current QBI thresholds for the tax year being tested. Consider whether to use specific numbers or general references."
  }
]
```

---

## Batch Size Recommendations

- **GPT-4o**: 25-50 questions per batch (balances context usage and review quality)
- **Gemini 1.5 Pro**: Can handle 100+ questions due to larger context window
- **Review time**: Allow model to be thorough - don't rush with low temperature

---

## Post-Review Process

1. **Approved questions**: Ready for import
2. **Needs-revision questions**:
   - Fix the flagged issues
   - Re-run through review (can batch all revisions together)
3. **Rejected questions**:
   - Evaluate if worth rewriting or should be discarded
   - If rewritten substantially, treat as new question for review

---

## Human Spot-Check Protocol

Even with AI review, sample 5-10% of questions for human verification:

1. Randomly select questions from each section
2. Prioritize reviewing:
   - Questions marked `accuracyConfidence: "medium"` or `"low"`
   - Calculation questions (verify the math)
   - Tax questions (most likely to have currency issues)
   - Any question the reviewer flagged uncertainty about

3. For each sampled question, verify:
   - [ ] Correct answer is definitely correct
   - [ ] Would pass muster on actual CPA exam
   - [ ] Explanation is helpful and accurate
   - [ ] No ambiguity in question stem or options

---

## Red Flags to Watch For

These patterns often indicate AI-generated content issues:

1. **"Textbook perfect" scenarios** - Real exam questions have messiness
2. **Round numbers in calculations** - Real exams use realistic figures
3. **All distractors being conceptual opposites** - Too clean/predictable
4. **Explanations that just restate the rule** - Should explain WHY
5. **Missing edge cases** - AI often gives the "happy path" answer
6. **Overly complex questions** - More complexity ≠ harder, often just confusing
7. **Tax questions with specific dollar thresholds** - These change annually
